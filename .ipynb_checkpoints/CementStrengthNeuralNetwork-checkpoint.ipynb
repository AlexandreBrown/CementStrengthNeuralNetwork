{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "norwegian-optimum",
   "metadata": {},
   "source": [
    "# Cement Strength Neural Network\n",
    "\n",
    "\n",
    "## Goal \n",
    "- Develop a neural network that can predict cement strength based on various features.\n",
    "\n",
    "## Approach\n",
    "- We will primarily be using Python and the deep learning library Keras to develop such solution.\n",
    "\n",
    "## Performance Evaluation\n",
    "- For the evaluation of our model, we will be using the mean squared error method (MSE) which can be represented by the following summation : $\\frac{1}{n} \\sum \\limits _{i=1} ^{n} (y_i - \\hat y_i)^2$\n",
    "    - Where $y_i$ is the actual value and $\\hat y_i$ is the prediction for a given sample $i$ from $n$ total samples.\n",
    "- We will try to minimize such sum in the process of building the solution.\n",
    "\n",
    "## Neural Network Architecture\n",
    "- Through multiple implementations, we will explore various neural network architectures. We should evaluate these different neural networks via our performance metrics in order to assess which one is the best at solving our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-webster",
   "metadata": {},
   "source": [
    "### Implementation details\n",
    "We will start by developing a neural network that consists of one hidden layer with 10 nodes and a ReLU activation function.\n",
    "<img src=\"https://i.ibb.co/31MmjTB/Neural-Network-Architecture-dot.png\" alt=\"Drawing\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-amazon",
   "metadata": {},
   "source": [
    "#### Dependencies\n",
    "First we need to install the keras library as well as tensorflow, since keras is based on tensorflow backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "increasing-contrary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/brownthedev/.local/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (3.16.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.30.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.4->tensorflow) (45.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.4->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/brownthedev/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/brownthedev/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/brownthedev/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/brownthedev/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/brownthedev/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 5.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Installing collected packages: pyasn1\n",
      "Successfully installed pyasn1-0.4.8\n",
      "/bin/bash: pip: command not found\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow && pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-powder",
   "metadata": {},
   "source": [
    "Once keras has been installed, we can import the needed dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "senior-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import InputLayer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-sequence",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "We will be using the same dataset that was used in lab3 about concrete compressive strength.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "national-academy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"https://cocl.us/concrete_data\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-distribution",
   "metadata": {},
   "source": [
    "Let's retrieve the X and y of this dataset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "judicial-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "yColumnName = 'Strength'\n",
    "\n",
    "X = dataset[dataset.columns[dataset.columns != yColumnName]]\n",
    "y = dataset[yColumnName]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-breathing",
   "metadata": {},
   "source": [
    "Let's take a look at our inputs and target values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "discrete-width",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  \n",
       "3             932.0           594.0  365  \n",
       "4             978.4           825.5  360  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reflected-cream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.99\n",
       "1    61.89\n",
       "2    40.27\n",
       "3    41.05\n",
       "4    44.30\n",
       "Name: Strength, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-myrtle",
   "metadata": {},
   "source": [
    "#### Building the neural network\n",
    "Here we define a class that represents a neural network. \n",
    "  \n",
    "With this class, we can build a neural network with some level of configuration.\n",
    "\n",
    "We decided to use the **_adam_** optimizer and the **_mean squared error_** as the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hourly-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        numberOfInputs,\n",
    "        numberOfHiddenLayers, \n",
    "        numberOfNodesInHiddenLayers\n",
    "    ):\n",
    "        self.numberOfInputs = numberOfInputs\n",
    "        self.numberOfHiddenLayers = numberOfHiddenLayers\n",
    "        self.numberOfNodesInHiddenLayers = numberOfNodesInHiddenLayers\n",
    "        self.__initializeModel()\n",
    "\n",
    "\n",
    "    def __initializeModel(self):\n",
    "        self.__createModel()\n",
    "        \n",
    "        self.__addInputLayer()\n",
    "        self.__addHiddenLayers()\n",
    "        self.__addOutputLayer()\n",
    "        \n",
    "        self.__compileModel()\n",
    "\n",
    "\n",
    "    def __createModel(self):\n",
    "        self.model = Sequential()\n",
    "\n",
    "\n",
    "    def __addInputLayer(self):\n",
    "        self.model.add(InputLayer(input_shape=(self.numberOfInputs,)))\n",
    "\n",
    "\n",
    "    def __addHiddenLayers(self):\n",
    "        for layer in range(self.numberOfHiddenLayers):\n",
    "            self.model.add(Dense(self.numberOfNodesInHiddenLayers, activation='relu'))\n",
    "\n",
    "\n",
    "    def __addOutputLayer(self):\n",
    "        self.model.add(Dense(1))\n",
    "\n",
    "\n",
    "    def __compileModel(self):\n",
    "        self.model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "    def undoLearning(self):\n",
    "        self.__initializeModel()\n",
    "\n",
    "\n",
    "    def train(\n",
    "        self, \n",
    "        inputs, \n",
    "        targetOutputs,\n",
    "        epochs\n",
    "    ):\n",
    "        self.model.fit(\n",
    "            inputs, \n",
    "            targetOutputs,\n",
    "            epochs=epochs,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        inputs\n",
    "    ):\n",
    "        return self.model.predict(inputs)\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\n",
    "                \"----------------------------------\\n\" +\n",
    "                \"Inputs: {}\\n\" + \n",
    "                \"Hidden layers count: {}\\n\" + \n",
    "                    \"\\tHidden layer nodes count: {}\" + \n",
    "                \"\\nOutputs: 1\\n\" +\n",
    "                \"----------------------------------\"\n",
    "               ).format(\n",
    "                    self.numberOfInputs, \n",
    "                    self.numberOfHiddenLayers, \n",
    "                    self.numberOfNodesInHiddenLayers\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-breed",
   "metadata": {},
   "source": [
    "We create a neural network for this first implementation with the desired configuration described earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accompanied-image",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Inputs: 8\n",
      "Hidden layers count: 1\n",
      "\tHidden layer nodes count: 10\n",
      "Outputs: 1\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "neuralNetwork1 = NeuralNetwork(\n",
    "    numberOfInputs=X.shape[1], \n",
    "    numberOfHiddenLayers=1,\n",
    "    numberOfNodesInHiddenLayers=10\n",
    ")\n",
    "print(neuralNetwork1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-papua",
   "metadata": {},
   "source": [
    "#### Training the neural network\n",
    "\n",
    "We will train our neural network with data that has been randomly split, we will reserve 30% of our dataset for test and use the remaining 70% for training.\n",
    "\n",
    "This way we will achieve out-of-sample testing.\n",
    "\n",
    "Note: If we wanted to obtain the same split every time we execute the code, we should consider using the parameter `random_state` of `train_test_split`. \n",
    "For more information, see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html.\n",
    "\n",
    "Here we did not want to control the shuffling so we left it to the default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "isolated-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndEvaluate(\n",
    "    neuralNetwork,\n",
    "    numberOfTrainingsToPerform,\n",
    "    epochsForEachTraining,\n",
    "    meanSquaredErrors,\n",
    "    predictors,\n",
    "    target\n",
    "):\n",
    "    print(\"Training started...\\n\")\n",
    "    for trainingNumber in range(numberOfTrainingsToPerform):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.30)\n",
    "    \n",
    "        neuralNetwork.train(X_train, y_train, epochs=epochsForEachTraining)\n",
    "    \n",
    "        predictions = neuralNetwork.predict(X_test)\n",
    "    \n",
    "        meanSquaredError = mean_squared_error(y_test, predictions)\n",
    "        meanSquaredErrors.append(meanSquaredError)\n",
    "\n",
    "    print(\"Training done!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "american-humor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "\n",
      "Training done!\n",
      "\n",
      "Mean: 69.34\n",
      "\n",
      "Standard deviation: 29.89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meanSquaredErrors1 = []\n",
    "\n",
    "trainAndEvaluate(\n",
    "    neuralNetwork=neuralNetwork1,\n",
    "    numberOfTrainingsToPerform=50,\n",
    "    epochsForEachTraining=50,\n",
    "    meanSquaredErrors=meanSquaredErrors1,\n",
    "    predictors=X,\n",
    "    target=y\n",
    ")\n",
    "\n",
    "meanOfMeanSquaredErrors1 = np.array(meanSquaredErrors1).mean()\n",
    "standardDeviationOfMeanSquaredErrors1 = np.array(meanSquaredErrors1).std()\n",
    "\n",
    "print(\"Mean: {:.2f}\\n\".format(meanOfMeanSquaredErrors1))\n",
    "print(\"Standard deviation: {:.2f}\\n\".format(standardDeviationOfMeanSquaredErrors1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-gates",
   "metadata": {},
   "source": [
    "### Data normalization experiment\n",
    "\n",
    "Let's repeat the same process, but this time, we will normalize the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "representative-comparison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedX = (X - X.mean()) / X.std()\n",
    "normalizedX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-fourth",
   "metadata": {},
   "source": [
    "Now that our inputs are normalized, we will undo the learning done previously and train it again but this time, with normalized data.\n",
    "\n",
    "Then we will compare the performance of our model with and without data normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-superior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neuralNetwork1.undoLearning()\n",
    "\n",
    "meanSquaredErrors2 = []\n",
    "\n",
    "trainAndEvaluate(\n",
    "    neuralNetwork=neuralNetwork1,\n",
    "    numberOfTrainingsToPerform=50,\n",
    "    epochsForEachTraining=50,\n",
    "    meanSquaredErrors=meanSquaredErrors2,\n",
    "    predictors=normalizedX,\n",
    "    target=y\n",
    ")\n",
    "\n",
    "meanOfMeanSquaredErrors2 = np.array(meanSquaredErrors2).mean()\n",
    "standardDeviationOfMeanSquaredErrors2 = np.array(meanSquaredErrors2).std()\n",
    "\n",
    "print(\"Mean without data normalization: {:.2f}\\n\".format(meanOfMeanSquaredErrors1))\n",
    "print(\"Mean with data normalization: {:.2f}\\n\".format(meanOfMeanSquaredErrors2))\n",
    "\n",
    "print(\"Standard deviation without data normalization: {:.2f}\\n\".format(standardDeviationOfMeanSquaredErrors1))\n",
    "print(\"Standard deviation with data normalization: {:.2f}\\n\".format(standardDeviationOfMeanSquaredErrors2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-granny",
   "metadata": {},
   "source": [
    "#### Results breakdown\n",
    "We can see that data normalization yielded gains in our model performance as the mean of the mean squared errors is a smaller with data normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-starter",
   "metadata": {},
   "source": [
    "### Number of epochs experiment\n",
    "Let's undo the learning of our model again and train it again with normalized data but this time, we will try **100 epochs** for training.\n",
    "\n",
    "Then let's compare the performance we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "maritime-olive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "\n",
      "Training done!\n",
      "\n",
      "Mean with data normalization (50 epochs): 50.48\n",
      "\n",
      "Mean with data normalization (100 epochs): 34.84\n",
      "\n",
      "Standard deviation with data normalization (50 epochs): 44.82\n",
      "\n",
      "Standard deviation with data normalization (100 epochs): 20.57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neuralNetwork1.undoLearning()\n",
    "\n",
    "meanSquaredErrors3 = []\n",
    "\n",
    "trainAndEvaluate(\n",
    "    neuralNetwork=neuralNetwork1,\n",
    "    numberOfTrainingsToPerform=50,\n",
    "    epochsForEachTraining=100,\n",
    "    meanSquaredErrors=meanSquaredErrors3,\n",
    "    predictors=normalizedX,\n",
    "    target=y\n",
    ")\n",
    "\n",
    "meanOfMeanSquaredErrors3 = np.array(meanSquaredErrors3).mean()\n",
    "standardDeviationOfMeanSquaredErrors3 = np.array(meanSquaredErrors3).std()\n",
    "\n",
    "print(\"Mean with data normalization (50 epochs): {:.2f}\\n\".format(meanOfMeanSquaredErrors2))\n",
    "print(\"Mean with data normalization (100 epochs): {:.2f}\\n\".format(meanOfMeanSquaredErrors3))\n",
    "\n",
    "print(\"Standard deviation with data normalization (50 epochs): {:.2f}\\n\".format(standardDeviationOfMeanSquaredErrors2))\n",
    "print(\"Standard deviation with data normalization (100 epochs): {:.2f}\\n\".format(standardDeviationOfMeanSquaredErrors3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-grace",
   "metadata": {},
   "source": [
    "#### Results breakdown\n",
    "We can see that performing more epochs when training can improve the performance of our model drastically.  \n",
    "That being said, it does not necessarily mean that doubling the epochs would **always** yield such a big impact, we can only confirm for 50 to 100.  \n",
    "Overall, we got a mean of the mean squared errors that was lower when training with 100 epochs comapred to 50 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-throat",
   "metadata": {},
   "source": [
    "### Number of hidden layers experiment\n",
    "Let's now create a neural network with a different architecture.  \n",
    "In the following implementation, we will create a neural network identical to the previous one but with 3 hidden layers instead of 1.\n",
    "\n",
    "<img src=\"https://i.ibb.co/wg7DnZw/Neural-Network-Architecture2-dot.png\" alt=\"Drawing\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "single-procedure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Inputs: 8\n",
      "Hidden layers count: 3\n",
      "\tHidden layer nodes count: 10\n",
      "Outputs: 1\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "neuralNetwork2 = NeuralNetwork(\n",
    "    numberOfInputs=X.shape[1], \n",
    "    numberOfHiddenLayers=3,\n",
    "    numberOfNodesInHiddenLayers=10\n",
    ")\n",
    "print(neuralNetwork2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-termination",
   "metadata": {},
   "source": [
    "#### Training the neural network\n",
    "We will use normalized data and 50 epochs for training and compare the results with the one from the initial neural network that had only 1 hidden layer, was using normalized data and 50 epochs as well for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "center-lounge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "\n",
      "Training done!\n",
      "\n",
      "Mean neural (network with 1 hidden layer): 50.48\n",
      "\n",
      "Mean neural (network with 3 hidden layers): 30.99\n",
      "\n",
      "Standard deviation (neural network with 1 hidden layer): 44.82\n",
      "\n",
      "Standard deviation (network with 3 hidden layers): 17.72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meanSquaredErrors4 = []\n",
    "\n",
    "trainAndEvaluate(\n",
    "    neuralNetwork=neuralNetwork2,\n",
    "    numberOfTrainingsToPerform=50,\n",
    "    epochsForEachTraining=50,\n",
    "    meanSquaredErrors=meanSquaredErrors4,\n",
    "    predictors=normalizedX,\n",
    "    target=y\n",
    ")\n",
    "\n",
    "meanOfMeanSquaredErrors4 = np.array(meanSquaredErrors4).mean()\n",
    "standardDeviationOfMeanSquaredErrors4 = np.array(meanSquaredErrors4).std()\n",
    "\n",
    "print(\"Mean (network with 1 hidden layer): {:.2f}\\n\".format(meanOfMeanSquaredErrors2))\n",
    "print(\"Mean (network with 3 hidden layers): {:.2f}\\n\".format(meanOfMeanSquaredErrors4))\n",
    "\n",
    "print(\"Standard deviation (neural network with 1 hidden layer): {:.2f}\\n\".format(standardDeviationOfMeanSquaredErrors2))\n",
    "print(\"Standard deviation (network with 3 hidden layers): {:.2f}\\n\".format(standardDeviationOfMeanSquaredErrors4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-necklace",
   "metadata": {},
   "source": [
    "#### Results breakdown\n",
    "We can observe that adding more layers can improve the performance of our model.  \n",
    "At least it was the case here when going from 1 hidden layer to 3.  \n",
    "This is explained by the lower mean obtained compared to the simpler neural network architecture.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
